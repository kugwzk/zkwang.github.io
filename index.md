---
layout: homepage
---

Hi, my name is Zekun Wang (汪泽堃 in Chinese). I am currently a final year Ph.D. student from SCIR @ Harbin Institute of Technology. Fortunately, I am advised by Prof. Ming Liu and Prof. Bin Qin. I expect to graduate in 2025. Prior to this, I received my bachelar degree from Harbin Institute of Technology n 2019.

My research interests have evolved to focus on developing: 
* Model/Data-Efficiency & Acceleration: Efficient architecture for XFMRs or hybrid ones; Pruning, distillation, quantization etc. to reduce model size and speedup inference; Efficient training LLMs/MLLMs with a small cost (time or data).

* Multi-modal Models and Applications: Large multi-modal models (comprehensive, generation, or unify the both), which support diverse tasks and can be applied as agents in digital or embodied environments.


I am particularly interested in exploring the intrinsic relationship between model (efficient) architecture and its performance, as well as how to unlock its potential in real-world scenarios.

 
### News:

* :fire::fire: Two papers have been accepted by ICLR'25. See you in Singapore!
* :fire: One paper has been accepted by COLING'25. See you in Abu Dhabi, UAE! 
* :rocket: [Qwen2.5 Technical Report](https://arxiv.org/abs/2412.15115) is released.

### Selected Publications:
Full publications can be found in [[Semantic Scholar](https://www.semanticscholar.org/author/Zekun-Wang/2108727290)] [[Google Scholar](https://scholar.google.com/citations?user=BrTJVdEAAAAJ)] (\* denotes equal contributions.)

* Improved Diffusion-based Generative Model with Better Adversarial Robustness <br>
**Zekun Wang**\*, Mingyang Yi\*, Shuchen Xue, Zhenguo Li, Ming Liu, Bing Qin, Zhi-Ming Ma<br>
**ICLR 2025** <br> 
[[pdf]](https://kugwzk.github.io/assets/pubs/iclr/2025/at_diff.pdf) <br>



* AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials <br>
Yiheng Xu, Dunjie Lu, Zhennan Shen, Junli Wang, **Zekun Wang**, Yuchen Mao, Caiming Xiong, Tao Yu <br>
**ICLR 2025 Spotlight**<br>
[[pdf]](https://arxiv.org/abs/2412.09605)
[[project]](https://agenttrek.github.io) <br>

* CFSP: An Efficient Structured Pruning Framework for LLMs with Coarse-to-Fine Activation Information <br>
Yuxin Wang\*, Minghua Ma\*, **Zekun Wang**\*, Jingchang Chen, Huiming Fan, Liping Shan, Qing Yang, Dongliang Xu, Ming Liu, Bing Qin. <br>
**COLING 2025**<br>
[[pdf]](https://aclanthology.org/2025.coling-main.626.pdf)
[[project]](https://github.com/wyxscir/CFSP) 
<br>

* Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-ofExpert Models <br>
Zihan Qiu, Zeyu Huang, Bo Zheng, Kaiyue Wen, **Zekun Wang**, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin <br>
**Preprint** 2025 <br>
[[pdf]](https://arxiv.org/abs/2501.11873)
<br>


* Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction <br>
Yiheng Xu\*, **Zekun Wang**\*, Junli Wang\*, Dunjie Lu, Tianbao Xie, Amrita Saha, Doyen Sahoo, Tao Yu, Caiming Xiong <br>
**Preprint** 2024 <br>
[[pdf]](https://arxiv.org/abs/2412.04454)
[[project]](https://aguvis-project.github.io/) 
<br>

* Qwen2.5 Technical Report <br>
Qwen Team <br>
**Technical Report** <br>
[[pdf]](https://arxiv.org/abs/2412.15115)
[[project]](https://github.com/QwenLM/Qwen2.5)
[[collection]](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e)
<br>
* Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation <br>
Jingchang Chen, Hongxuan Tang, Zheng Chu, Qianglong Chen, **Zekun Wang**, Ming Liu, Bing Qin <br>
**NeurIPS 2024 Oral** <br>
[[pdf]](https://arxiv.org/abs/2405.20092) <br>

* SmartTrim: Adaptive Tokens and Attention Pruning for Efficient Vision-Language Models <br>
**Zekun Wang**\*, **Jingchang Chen**\*, Wangchunshu Zhou, Haichao Zhu, Jiafeng Liang, Liping Shan, Ming Liu, Dongliang Xu, Qing Yang, Bing Qin <br>
**COLING 2024 Oral** <br>
[[pdf]](https://aclanthology.org/2024.lrec-main.1300.pdf) <br>

* Distilled Dual-Encoder Model for Vision-Language Understanding <br>
**Zekun Wang**, Wenhui Wang, Haichao Zhu, Ming Liu, Bing Qin, Furu Wei <br>
**EMNLP 2022**
[[pdf]](https://aclanthology.org/2022.emnlp-main.608.pdf)
[[project]](https://github.com/kugwzk/DiDE)

* Less Is More: Domain Adaptation with Lottery Ticket for Reading Comprehension <br>
Haichao Zhu, **Zekun Wang**, Heng Zhang, Ming Liu, Sendong Zhao, Bing Qin <br>
**Findings of EMNLP 2021** <br>
[[pdf]](https://aclanthology.org/2021.findings-emnlp.95/) <br>

<!-- ### Projects: -->


<!-- ### Experience -->

